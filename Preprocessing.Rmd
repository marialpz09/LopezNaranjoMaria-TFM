---
title: "Data Preprocessing and Quality Control"
output:
  html_document: default
  word_document: default
  pdf_document: default
date: "2024-03-19"
---




**The preprocessing of samples is the first step to be performed with our Single-cell RNA samples.**  
This processing includes: QC (quality control), data filtering, dimensionality reduction using PCA analysis (linear relationships), and UMAP (non-linear relationships).

Additionally, batch effect correction will be performed, which is typical noise from samples of the same omics (RNA-seq in our case).  
Finally, we will integrate all our data.

## **Loading libraries:**  

```{r, warning=FALSE}
library(dplyr)
library(patchwork)
library(stringr)
library(ggplot2)
library(ggpubr)
library(cowplot)
library(tidyr)
library(openxlsx)
library(writexl)
#remotes::install_github('chris-mcginnis-ucsf/DoubletFinder')
library(DoubletFinder)
library(Seurat)
```




We load the enriched samples. These are our raw data.
```{r,  eval=FALSE}
sm1HI.data =Read10X("sm1HI/filtered_feature_bc_matrix")
sm2HI.data =Read10X("sm2HI/filtered_feature_bc_matrix")
sm8SHAM.data =Read10X("sm8SHAM/filtered_feature_bc_matrix")
sm9SHAM.data =Read10X("sm9SHAM/filtered_feature_bc_matrix")
```
The obtained data is stored in Seurat Object format for single-cell.

This object will cotain the count matriz and and subsequent analyses.


```{r,  eval=FALSE}
sm1HI <- CreateSeuratObject(counts = sm1HI.data, project = "sm1HI", min.cells = 3, min.features = 200)

sm2HI <- CreateSeuratObject(counts = sm2HI.data, project = "sm2HI", min.cells = 3, min.features = 200)

sm8SHAM<- CreateSeuratObject(counts = sm8SHAM.data, project = "sm8SHAM", min.cells = 3, min.features = 200)

sm9SHAM<- CreateSeuratObject(counts = sm9SHAM.data, project = "sm9SHAM", min.cells = 3, min.features = 200)

```



```{r,  eval=FALSE}
sm1HI[["percent.mt"]] <- PercentageFeatureSet(sm1HI, pattern = "^mt")
sm2HI[["percent.mt"]] <- PercentageFeatureSet(sm2HI, pattern = "^mt")
sm8SHAM[["percent.mt"]] <- PercentageFeatureSet(sm8SHAM, pattern = "^mt")
sm9SHAM[["percent.mt"]] <- PercentageFeatureSet(sm9SHAM, pattern = "^mt")
```


## Quality Filtering  

 Next, we proceed to perform quality control on each sample individually.
For quality filtering, we will remove cells with low gene counts, doublets, and cells with excessive mitochondrial activity.

The graphs shown below detail the percentage of mitochondrial RNA present, RNA counts, and genes.

We visualize the quality of our data:
```{r,  eval=FALSE}


png("sm1HIquality.png", width = 800, height = 600, res = 120)
VlnPlot(sm1HI, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

dev.off()

png("sm2HIquality.png", width = 800, height = 600, res = 120)
VlnPlot(sm2HI, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

dev.off()
png("sm8SHAMquality.png", width = 800, height = 600, res = 120)
VlnPlot(sm8SHAM, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

dev.off()

png("sm9SHAMquality.png", width = 800, height = 600, res = 120)
VlnPlot(sm9SHAM, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

dev.off()

```

```{r,  eval=FALSE}
plot1 <- FeatureScatter(sm1HI, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(sm1HI, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

png("sm1HIpercentagequality.png", width = 1200, height = 600, res = 120)
plot1 + plot2

dev.off() 


plot3 <- FeatureScatter(sm2HI, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot4 <- FeatureScatter(sm2HI, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

png("sm2HIpercentagequality.png", width = 1200, height = 600, res = 120)
plot3 + plot4

dev.off() 

plot5 <- FeatureScatter(sm8SHAM, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot6 <- FeatureScatter(sm8SHAM, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

png("sm8SHAMpercentagequality.png", width = 1200, height = 600, res = 120)
plot5 + plot6

dev.off() 

plot7 <- FeatureScatter(sm9SHAM, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot8 <- FeatureScatter(sm9SHAM, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

png("sm9SHAMpercentagequality.png", width = 1200, height = 600, res = 120)
plot7 + plot8

dev.off() 

```

![nFeature_RNA, nCount_RNA, percentage.mt](sm1HI/imagenes y tablas sm1HI/sm1HIquality.png)


![Plot1+ Plot 2](sm1HI/imagenes y tablas sm1HI/sm1HIpercentagequality.png)
What we have done is visualize our data, showing the percentage of mitochondrial cells, which indicates the presence of apoptotic and/or dead cells that need to be removed.

With the following code, we will filter out cells with low expression (fewer than 200 genes) and more than 5000 to prevent doublets from being included. As mentioned, we will also remove cells with a mitochondrial RNA percentage greater than 5%.
```{r,  eval=FALSE}
sm1HI_filtrado<- subset(sm1HI, subset = nFeature_RNA > 200 & nFeature_RNA < 5000 & percent.mt < 5)
sm2HI_filtrado<- subset(sm2HI, subset = nFeature_RNA > 200 & nFeature_RNA < 5000 & percent.mt < 5)
sm8SHAM_filtrado<- subset(sm8SHAM, subset = nFeature_RNA > 200 & nFeature_RNA < 5000 & percent.mt < 5)
sm9SHAM_filtrado<- subset(sm9SHAM, subset = nFeature_RNA > 200 & nFeature_RNA < 5000 & percent.mt < 5)
```


Checkpoint.We save our raw data in a excel. This is very helpful for comparing our filtered data.
```{r,  eval=FALSE}

write_xlsx(sm1HI@meta.data, "sm1HISinFiltrar.xlsx")
write_xlsx(sm2HI@meta.data, "sm2HISinFiltrar.xlsx")
write_xlsx(sm8SHAM@meta.data, "sm8SHAMSinFiltrar.xlsx")
write_xlsx(sm9SHAM@meta.data, "sm9SHAMSinFiltrar.xlsx")
```

Let´s generate a table with all the filtering information:

```{r,  eval=FALSE}

tabla_sin_filtrar <- table(c(sm1HI$orig.ident, sm2HI$orig.ident, sm8SHAM$orig.ident, sm9SHAM$orig.ident))
tabla_filtrados <- table(c(sm1HI_filtrado$orig.ident, sm2HI_filtrado$orig.ident, sm8SHAM_filtrado$orig.ident, sm9SHAM_filtrado$orig.ident))


df_sin_filtrar <- as.data.frame(tabla_sin_filtrar)
df_filtrados <- as.data.frame(tabla_filtrados)

df_sin_filtrar$Estado <- "SIN FILTRAR"
df_filtrados$Estado <- "FILTRADOS"

df_combinado <- rbind(df_sin_filtrar, df_filtrados)

print(df_combinado)
write_xlsx(df_combinado, "RecuentoAntesVsDespuesFiltro.xlsx")

suma_sin_filtrar <- sum(tabla_sin_filtrar)
suma_filtrados <- sum(tabla_filtrados)

df_totales <- data.frame(
  Estado = c("ANTES DE FILTRAR", "FILTRADO"),
  Total = c(suma_sin_filtrar, suma_filtrados)
)

# Mostrar el data frame de totales
print(df_totales)

```

| Sample   | Count  | Status      |
|----------|--------|-------------|
| sm1HI    | 10328  | Unfiltered   |
| sm2HI    | 12188  | Unfiltered   |
| sm8SHAM  | 10402  | Unfiltered   |
| sm9SHAM  | 10691  | Unfiltered   |
| sm1HI    | 9977   | Filtered     |
| sm2HI    | 11547  | Filtered     |
| sm8SHAM  | 9863   | Filtered     |
| sm9SHAM  | 10474  | Filtered     |

Before filtering: 43609			
After Filtering:	41861

After that, let´s check that our filtering process has good results.
```{r,  eval=FALSE}
# We ensure that the percentage of mitochondrial (MT) cells does not exceed 5%.
p1 <- VlnPlot (sm2HI_filtrado, features = "nFeature_RNA", slot = "counts") + ylim(0,30000)
p2 <- VlnPlot(sm2HI_filtrado, features = "nCount_RNA", slot = "counts") + ylim(0,30000)
                                                                                      
                                                                                    
p3 <- VlnPlot(sm2HI_filtrado, features = "percent.mt", slot = "counts") +ylim(0,30000)
plot_grid(p1, p2, p3, ncol = 3)


p4 <- VlnPlot (sm2HI, features = "percent.mt", slot = "counts") +ylim(0,100)
p5 =VlnPlot (sm2HI_filtrado,features = "percent.mt", slot = "counts") +ylim(0,100)
plot_grid(p4,p5, ncol=2)
```

![Filtered data](datos.integrated.sorted/data.filtered.png)
![RNA mithocondrial zoomed](datos.integrated.sorted/percentMT.png)
In these graphs, we can observe the filtered data and the comparison of the remaining mitochondrial cells, for example, in the sample sm2HI.


## Normalize:
the function “NormalizeData” is going to be used with Seurat default values. This function “normalizes the expression measurements of the features of each cell by the total expression, multiplies this by a scale factor (10,000 by default).”
```{r,  eval=FALSE} 
sm1HI_filtrado<- NormalizeData(object= sm1HI_filtrado)
sm2HI_filtrado<- NormalizeData(object= sm2HI_filtrado)
sm8SHAM_filtrado<- NormalizeData(object= sm8SHAM_filtrado)
sm9SHAM_filtrado<- NormalizeData(object= sm9SHAM_filtrado)
```

## FindVariableFeatures:
With this function, we get the variable features of each sample
```{r,  eval=FALSE}

sm1HI_filtrado= FindVariableFeatures(sm1HI_filtrado)
sm2HI_filtrado= FindVariableFeatures(sm2HI_filtrado)
sm8SHAM_filtrado= FindVariableFeatures(sm8SHAM_filtrado)
sm9SHAM_filtrado= FindVariableFeatures(sm9SHAM_filtrado)
```
## Scaling:
Scaled Data means: mean of 0 between cells and a variance of 1 between cells.
```{r,  eval=FALSE}
 
sm1HI_filtrado<- ScaleData(object= sm1HI_filtrado)
sm2HI_filtrado<- ScaleData(object= sm2HI_filtrado)
sm8SHAM_filtrado<- ScaleData(object= sm8SHAM_filtrado)
sm9SHAM_filtrado<- ScaleData(object= sm9SHAM_filtrado)
```

## Erythrocyte clearance
As blood samples, a certain number of red blood cells are expected to be present in each sample. As they are not of interest for our further analysis, we will eliminate cells expressing the “Hbb-bt” gene (gene involved in haemoglobin synthesis). So after scaling, we eliminate this type of cells from our samples.

```{r,  eval=FALSE}

sm1HI_filtradoTotal= subset(sm1HI_filtrado,subset = `Hbb-bt` < 1)
sm2HI_filtradoTotal= subset(sm2HI_filtrado,subset = `Hbb-bt` < 1)
sm8SHAM_filtradoTotal= subset(sm8SHAM_filtrado,subset = `Hbb-bt` < 1)
sm9SHAM_filtradoTotal= subset(sm9SHAM_filtrado,subset = `Hbb-bt` < 1)
```


Let´s generate a table to compare samples with this new filter:
```{r,  eval=FALSE}

  tabla_filtradosTOTAL <- table(c(sm1HI_filtradoTotal$orig.ident, sm2HI_filtradoTotal$orig.ident, sm8SHAM_filtradoTotal$orig.ident, sm9SHAM_filtradoTotal$orig.ident))

# Convertir las tablas en data frames

df_filtradostotales <- as.data.frame(tabla_filtradosTOTAL)

# Añadir una columna para indicar el estado (SIN FILTRAR o FILTRADOS)
df_filtradostotales$Estado <- "SIN HBB-BT"
df_filtrados$Estado <- "FILTRADOS PERO CON HBB-BT"

# Combinar los data frames
df <- rbind(df_filtradostotales, df_filtrados)

# Mostrar el data frame combinado
print(df)
write_xlsx(df, "RecuentoSinHBB-BT.xlsx")

suma_sinhhbt <- sum(tabla_filtradosTOTAL)
suma_filtrados <- sum(tabla_filtrados)

# Crear un data frame para los totales
sumadf <- data.frame(
  Estado = c("FILTRADO", "FILTRADO SIN HBB-BT" ),
  Total = c(suma_filtrados, suma_sinhhbt))


# Mostrar el data frame de totales
print(sumadf)
```
| Sample   | Count  | Status                                |
|----------|--------|---------------------------------------|
| sm1HI    | 7090   | Without HBB-BT                        |
| sm2HI    | 8206   | Without HBB-BT                        |
| sm8SHAM  | 6033   | Without HBB-BT                        |
| sm9SHAM  | 7215   | Without HBB-BT                        |
| sm1HI    | 9977   | Filtered but with HBB-BT              |
| sm2HI    | 11547  | Filtered but with HBB-BT              |
| sm8SHAM  | 9863   | Filtered but with HBB-BT              |
| sm9SHAM  | 10474  | Filtered but with HBB-BT              |



| Status                        | Total Cells |
|-------------------------------|-------------|
| Filtered  Step 1              | 41861       |
| Filtered and Without HBB-BT   | 28544       |


Therefore, after removing erythrocytes, we have a total of 28,544 cells

## PCA
We perform dimensionality reduction using PCA. Principal Component Analysis (PCA) is a statistical technique used for dimensionality reduction. It helps simplify complex datasets by transforming them into a smaller set of variables, called principal components, while retaining as much of the original data's variation as possible.
```{r,  eval=FALSE}
sm1HI_filtradoTotal = RunPCA(object= sm1HI_filtradoTotal)
sm2HI_filtradoTotal = RunPCA(object= sm2HI_filtradoTotal)
sm8SHAM_filtradoTotal = RunPCA(object= sm8SHAM_filtradoTotal)
sm9SHAM_filtradoTotal = RunPCA(object= sm9SHAM_filtradoTotal)


```


This graph is necessary to select the dimensionality of our dataset. Specifically, the elbow plot ranks the components based on the percentage of variance they explain in the data. We will perform one elbowplot for each sample.
```{r,  eval=FALSE}
ElbowPlot(sm1HI_filtradoTotal)
ElbowPlot(sm2HI_filtradoTotal)
ElbowPlot(sm8SHAM_filtradoTotal)
ElbowPlot(sm9SHAM_filtradoTotal)
```

![Example of Elbowplot](datos.integrated.sorted/elbowplot.example.png)
We will choose 20 PC for each sample.

After performing PCA, we will carry out dimensionality reduction using UMAP, which, unlike PCA, works with non-linear variables.

## UMAP

UMAP (Uniform Manifold Approximation and Projection) is a non-linear dimensionality reduction technique that is widely used for visualizing high-dimensional data. It preserves the local and global structure of data better than many other methods, making it highly effective for tasks such as clustering, visualization, and exploration of complex datasets.

```{r,  eval=FALSE}
# sm1HI
sm1HI_filtradoTotal= FindNeighbors(object=sm1HI_filtradoTotal, dims=1:20)
sm1HI_filtradoTotal=FindClusters(sm1HI_filtradoTotal)
sm1HI_filtradoTotal= RunUMAP(object=sm1HI_filtradoTotal, dims =1:20)

# sm2HI
sm2HI_filtradoTotal= FindNeighbors(object=sm2HI_filtradoTotal, dims=1:20)
sm2HI_filtradoTotal=FindClusters(sm2HI_filtradoTotal)
sm2HI_filtradoTotal= RunUMAP(object=sm2HI_filtradoTotal, dims =1:20)

# sm8SHAM
sm8SHAM_filtradoTotal= FindNeighbors(object=sm8SHAM_filtradoTotal, dims=1:20)
sm8SHAM_filtradoTotal=FindClusters(sm8SHAM_filtradoTotal)
sm8SHAM_filtradoTotal= RunUMAP(object=sm8SHAM_filtradoTotal, dims =1:20)

# sm9SHAM
sm9SHAM_filtradoTotal= FindNeighbors(object=sm9SHAM_filtradoTotal, dims=1:20)
sm9SHAM_filtradoTotal=FindClusters(sm9SHAM_filtradoTotal)
sm9SHAM_filtradoTotal= RunUMAP(object=sm9SHAM_filtradoTotal, dims =1:20)
```

We visualize the UMAP for each sample:

```{r,  eval=FALSE}
DimPlot(sm1HI_filtradoTotal, reduction="umap") + ggtitle ("sm1HI")
DimPlot(sm2HI_filtradoTotal, reduction= "umap") + ggtitle ("sm2HI")
DimPlot(sm8SHAM_filtradoTotal, reduction="umap") + ggtitle ("sm8SHAM")
DimPlot(sm9SHAM_filtradoTotal, reduction="umap") + ggtitle ("sm9SHAM")

```

Next, we will remove any doublets that may have remained despite the previous filtering.

## DoubletFinder: Parameters

Once we have the UMAP for each sample, we use the `doubletFinder` function, which identifies clusters in our plot of cells that are likely to be doublets.


```{r,  eval=FALSE}

sweep.res.list_sm1HI <- paramSweep(sm1HI_filtradoTotal, PCs = 1:20, sct = FALSE)
sweep.stats_sm1HI<- summarizeSweep(sweep.res.list_sm1HI, GT = FALSE)
bcmvn_sm1HI<- find.pK(sweep.stats_sm1HI)
```
```{r,  eval=FALSE}
ggplot(bcmvn_sm1HI, aes(pK, BCmetric, group=1)) + geom_point() + geom_line()

```

```{r,  eval=FALSE}
pK1HI=bcmvn_sm1HI %>% filter(BCmetric == max(BCmetric)) %>% select(pK)
pK1HI = as.numeric(as.character(pK1HI[[1]]))
```



```{r,  eval=FALSE}

annotations.1HI = sm1HI_filtradoTotal@meta.data$seurat_clusters
homotypic.prop.1HI = modelHomotypic(annotations.1HI)
nExp_noi =round(0.076*nrow((sm1HI_filtradoTotal@meta.data)))
nExp_noi.adj= round(nExp_noi * (1- homotypic.prop.1HI))
```


Once we have our parameters, **pk**, **pn**, and **exp_noi** adjusted.
# We calculate the doublets.
```{r,  eval=FALSE}
sm1HI_filtradoTotal=doubletFinder(sm1HI_filtradoTotal, PCs=1:20, pN=0.25, pK=pK1HI, nExp=nExp_noi.adj, reuse.pANN = FALSE, sct=FALSE)
```


We can see in the metadata that there is a new column that classifies whether the cells are doublets or not.

```{r,  eval=FALSE}
DimPlot(sm1HI_filtradoTotal, reduction="umap", group.by = "DF.classifications_0.25_0.28_492")
```

We observe that a few cells are classified as doublets and need to be removed.
```{r,  eval=FALSE}
table(sm1HI_filtradoTotal@meta.data$DF.classifications_0.25_0.27_491)
```
|Doublet |Singlet |
|    491 |   6599 |
    
In this next function we eliminate the doublets.
```{r,  eval=FALSE}


#Create a new Seurat object with the filtered cells.
sm1HI.singlet <- subset(sm1HI_filtradoTotal, cells = WhichCells(sm1HI_filtradoTotal, expression = DF.classifications_0.25_0.28_492 == "Singlet"))



```

Next, we perform the same process for the other samples:
parameter search.
```{r,  eval=FALSE}
#sm2HI
sweep.res.list_sm2HI <- paramSweep(sm2HI_filtradoTotal, PCs = 1:20, sct = FALSE)
sweep.stats_sm2HI<- summarizeSweep(sweep.res.list_sm2HI, GT = FALSE)
bcmvn_sm2HI<- find.pK(sweep.stats_sm2HI)

#sm8SHAM
sweep.res.list_sm8SHAM <- paramSweep(sm8SHAM_filtradoTotal, PCs = 1:20, sct = FALSE)
sweep.stats_sm8SHAM<- summarizeSweep(sweep.res.list_sm8SHAM, GT = FALSE)
bcmvn_sm8SHAM<- find.pK(sweep.stats_sm8SHAM)

#sm9SHAM
sweep.res.list_sm9SHAM <- paramSweep(sm9SHAM_filtradoTotal, PCs = 1:20, sct = FALSE)
sweep.stats_sm9SHAM<- summarizeSweep(sweep.res.list_sm9SHAM, GT = FALSE)
bcmvn_sm9SHAM<- find.pK(sweep.stats_sm9SHAM)
```
```{r,  eval=FALSE}
ggplot(bcmvn_sm2HI, aes(pK, BCmetric, group=1)) + geom_point() + geom_line()
ggplot(bcmvn_sm8SHAM, aes(pK, BCmetric, group=1)) + geom_point() + geom_line()
ggplot(bcmvn_sm9SHAM, aes(pK, BCmetric, group=1)) + geom_point() + geom_line()
```

```{r,  eval=FALSE}
pK2HI=bcmvn_sm2HI %>% filter(BCmetric == max(BCmetric)) %>% select(pK)
pK2HI = as.numeric(as.character(pK2HI[[1]]))

pK8SHAM=bcmvn_sm8SHAM %>% filter(BCmetric == max(BCmetric)) %>% select(pK)
pK8SHAM = as.numeric(as.character(pK8SHAM[[1]]))

pK9SHAM=bcmvn_sm9SHAM %>% filter(BCmetric == max(BCmetric)) %>% select(pK)
pK9SHAM = as.numeric(as.character(pK9SHAM[[1]]))
```


```{r,  eval=FALSE}
#we search for the doublets:

#sm2hi
annotations.2HI = sm2HI_filtradoTotal@meta.data$seurat_clusters
homotypic.prop.2HI = modelHomotypic(annotations.2HI)
nExp_noi2 =round(0.076*nrow((sm2HI_filtradoTotal@meta.data)))
nExp_noi.adj2= round(nExp_noi2 * (1- homotypic.prop.2HI))

#sm8SHAM
annotations.8SHAM = sm8SHAM_filtradoTotal@meta.data$seurat_clusters
homotypic.prop.8SHAM= modelHomotypic(annotations.8SHAM)
nExp_noi8 =round(0.076*nrow((sm8SHAM_filtradoTotal@meta.data)))
nExp_noi.adj8= round(nExp_noi8 * (1- homotypic.prop.8SHAM))

#sm9SHAM
annotations.9SHAM = sm9SHAM_filtradoTotal@meta.data$seurat_clusters
homotypic.prop.9SHAM= modelHomotypic(annotations.9SHAM)
nExp_noi9 =round(0.076*nrow((sm9SHAM_filtradoTotal@meta.data)))
nExp_noi.adj9= round(nExp_noi9 * (1- homotypic.prop.9SHAM))


```

Doublets found and removed by sample:

sm1HI| sm2HI |sm8SHAM| sm9SHAM |
 491 |  563  |  409  | 486     |


```{r,  eval=FALSE}
sm2HI_filtradoTotal=doubletFinder(sm2HI_filtradoTotal, PCs=1:20, pN=0.25, pK=pK2HI, nExp=nExp_noi.adj2, reuse.pANN = FALSE, sct=FALSE)

sm8SHAM_filtradoTotal=doubletFinder(sm8SHAM_filtradoTotal, PCs=1:20, pN=0.25, pK=pK8SHAM, nExp=nExp_noi.adj8, reuse.pANN = FALSE, sct=FALSE)

sm9SHAM_filtradoTotal=doubletFinder(sm9SHAM_filtradoTotal, PCs=1:20, pN=0.25, pK=pK9SHAM, nExp=nExp_noi.adj9, reuse.pANN = FALSE, sct=FALSE)
```

```{r,  eval=FALSE}

DimPlot(sm2HI_filtradoTotal, reduction="umap", group.by = "DF.classifications_0.25_0.16_565") + ggtitle("sm2HI")

DimPlot(sm8SHAM_filtradoTotal, reduction="umap", group.by = "DF.classifications_0.25_0.3_409") + ggtitle("sm8SHAM")

DimPlot(sm9SHAM_filtradoTotal, reduction="umap", group.by = "DF.classifications_0.25_0.26_486") + ggtitle("sm9SHAM")
```


## Checkpoint

Up to this point, our samples called **filteredTotal** had filters for mitochondrial content, minimum and maximum RNA, and erythrocytes.  
The new samples without doublets will have the extension **.singlet**.




We permanently remove the doublets:
```{r,  eval=FALSE}
sm1HI.singlet<- subset(x = sm1HI_filtradoTotal, subset = DF.classifications_0.25_0.28_492 == "Singlet")

sm2HI.singlet<- subset(x = sm2HI_filtradoTotal, subset = DF.classifications_0.25_0.16_565== "Singlet")
sm8SHAM.singlet<- subset(x = sm8SHAM_filtradoTotal, subset = DF.classifications_0.25_0.3_409== "Singlet")
sm9SHAM.singlet<- subset(x = sm9SHAM_filtradoTotal, subset = DF.classifications_0.25_0.26_486== "Singlet")

# We check it:

table(sm1HI.singlet@meta.data$DF.classifications_0.25_0.28_492)


table(sm2HI.singlet@meta.data$DF.classifications_0.25_0.16_565)
table(sm8SHAM.singlet@meta.data$DF.classifications_0.25_0.3_409)
table(sm9SHAM.singlet@meta.data$DF.classifications_0.25_0.26_486)

```



```{r,  eval=FALSE}

tablaSINDOUBLETS= table(c(sm1HI.singlet$orig.ident, sm2HI.singlet$orig.ident, 
                          sm8SHAM.singlet$orig.ident, sm9SHAM.singlet$orig.ident  ))
# Convertir las tablas en data frames
df_singlet <- as.data.frame(tablaSINDOUBLETS)


# Añadir una columna para indicar el estado (SIN FILTRAR o FILTRADOS)
df_singlet$Estado <- "SIN DOUBLETS"


# Combinar los data frames
df_final<- rbind(df_sin_filtrar, df_filtrados, df_filtradostotales, df_singlet)

# Mostrar el data frame combinado
print(df_final)
write_xlsx(df_final, "RecuentofinalPrepocesamiento.xlsx")

suma_singlet =sum(tablaSINDOUBLETS)
# Crear un data frame para los totales
df_finalprep <- data.frame(
  Estado = c("ANTES DE FILTRAR", "FILTRADO", "SIN HBB-BT", "SIN DOUBLETS"),
  Total = c(suma_sin_filtrar, suma_filtrados, suma_sinhhbt, suma_singlet)
)

# Mostrar el data frame de totales
print(df_finalprep)
```

|Raw data           |	 43609	|	
|Step 1 QC          |  41861	|	
|Step 2 HBB-BT      |  28544	|	
|Step 3 Doublets    |  26592  |
|HI AFTER FILTERS   |  14239  |
|SHAM AFTER FILTERS |  12353  |



```{r,  eval=FALSE}


  sm1HI.singlet@meta.data$pANN_0.25_0.28_492<- NULL
 sm1HI.singlet@meta.data$DF.classifications_0.25_0.28_492<- NULL
sm2HI.singlet@meta.data$pANN_0.25_0.16_565 <- NULL
 sm2HI.singlet@meta.data$DF.classifications_0.25_0.16_565<- NULL
  sm8SHAM.singlet@meta.data$pANN_0.25_0.3_409<- NULL
  sm8SHAM.singlet@meta.data$DF.classifications_0.25_0.3_409<- NULL
 sm9SHAM.singlet@meta.data$pANN_0.25_0.26_486<- NULL
  sm9SHAM.singlet@meta.data$DF.classifications_0.25_0.26_486<- NULL


```



### Integration of the samples 

Once we have our samples well processed, we proceed to integrate our data.  
#The first step for integration is doing a Merge from all the samples.
In the next step, we add the samples to the same Seurat object (the first step for data integration).


```{r,  eval=FALSE}

datos.sorted<- merge(sm1HI.singlet, c(sm2HI.singlet, sm8SHAM.singlet, sm9SHAM.singlet), 
              add.cell.ids = c("sm1HI", "sm2HI", "sm8SHAM", "sm9SHAM"))
```

We explore our meta.data
```{r,  eval=FALSE}
View(datos.sorted@meta.data)

```

In the following table, we see the number of cells we have after preprocessing for each of the samples.
```{r,  eval=FALSE}

table(datos.sorted$orig.ident)

```

What we do with the following function is divide our data by sample. The data from the samples can be found in the metadata.

```{r,  eval=FALSE}
unique(sapply(X = strsplit(colnames(datos.sorted), split = "_"), FUN = "[", 1))
sample <- datos.sorted@meta.data$orig.ident 
datos.sorted@meta.data$sample <- sample
Idents(object = datos.sorted) <- "sample"

#datos.sorted@meta.data
```




With the following code, we divide the samples according to the condition: **SHAM** for control and **HI** for treatment.
```{r,eval=FALSE}
datos.sorted@meta.data$condition <- NA


datos.sorted@meta.data$condition[which(str_detect(datos.sorted@meta.data$orig.ident, "sm1HI"))] <- "HI"

datos.sorted@meta.data$condition[which(str_detect(datos.sorted@meta.data$orig.ident, "sm2HI"))] <- "HI"

datos.sorted@meta.data$condition[which(str_detect(datos.sorted@meta.data$orig.ident, "sm8SHAM"))] <- "SHAM"

datos.sorted@meta.data$condition[which(str_detect(datos.sorted@meta.data$orig.ident, "sm9SHAM"))] <- "SHAM"
```
With the following, we confirm that only this type of condition exists and that no NA values have been included.
```{r,  eval=FALSE}
unique(datos.sorted @meta.data$condition)
```
```{r,  eval=FALSE}
datos.sorted@meta.data$procedure <- NA


datos.sorted@meta.data$procedure[which(str_detect(datos.sorted@meta.data$orig.ident, "sm1HI"))] <- "sorted"

datos.sorted@meta.data$procedure[which(str_detect(datos.sorted@meta.data$orig.ident, "sm2HI"))] <- "sorted"

datos.sorted@meta.data$procedure[which(str_detect(datos.sorted@meta.data$orig.ident, "sm8SHAM"))] <- "sorted"

datos.sorted@meta.data$procedure[which(str_detect(datos.sorted@meta.data$orig.ident, "sm9SHAM"))] <- "sorted"


```

```{r,  eval=FALSE}
unique(datos.sorted@meta.data$procedure)
```


Additionally, we group the samples according to the day the experiment was conducted:  
- **Sm1HI** and **sm8SHAM** correspond to experiment 1.  
- **Sm2HI** and **sm9SHAM** correspond to experiment 2.
```{r,  eval=FALSE}
datos.sorted@meta.data$experimento=NA
datos.sorted@meta.data$experimento[which(str_detect(datos.sorted@meta.data$orig.ident, "sm1HI"))]= "EXP1"
datos.sorted@meta.data$experimento[which(str_detect(datos.sorted@meta.data$orig.ident, "sm2HI"))]= "EXP2"
datos.sorted@meta.data$experimento[which(str_detect(datos.sorted@meta.data$orig.ident, "sm8SHAM"))]= "EXP1"
datos.sorted@meta.data$experimento[which(str_detect(datos.sorted@meta.data$orig.ident, "sm9SHAM"))]= "EXP2"

unique(datos.sorted @meta.data$experimento)
```


## Normalize
What we will do next will help us observe if there is a batch effect.

With the data combined, we will normalize it again.
```{r,  eval=FALSE}
datos.sorted= NormalizeData(object=datos.sorted)
datos.sorted=FindVariableFeatures(datos.sorted)
datos.sorted=ScaleData(object=datos.sorted)
datos.sorted=RunPCA(object=datos.sorted)
ElbowPlot(datos.sorted)
```
![ElbowPlot for "merge" samples](datos.integrated.sorted/elbowplotmerge.png)


## UMAP for Merge

```{r, eval=FALSE}
datos.sorted= FindNeighbors(object=datos.sorted, dims=1:20)
datos.sorted=FindClusters(datos.sorted)
datos.sorted= RunUMAP(object=datos.sorted, dims =1:20)

#PLOTS:
DimPlot(datos.sorted, reduction="umap", group.by="sample")
DimPlot(datos.sorted, reduction= "umap", group.by="condition")
DimPlot(datos.sorted, reduction="umap", group.by = "experimento")

```
We separate our samples by treatment or control for better visualization in the UMAP plot.

![Plot for merge sample divided for condition](mergeHIvsSHAM.png)
![Plot for merge sample divided for experiment](datos.integrated.sorted/mergeExperimento.png)
![[Plot for merge sample divided for sample](datos.integrated.sorted/mergeSAMPLES.png)

```{r,  eval=FALSE}
write_xlsx(datos.sorted@meta.data, "datos.sorted.xlsx")
```


## Batch efect.


To avoid the batch effect in our samples, we perform normalization on each of them, as well as select the most variable genes for each cell.  
Previously, the Seurat object has been divided by "sample," meaning by samples, using the `SplitObject` command.

**Normalize**
```{r,  eval=FALSE}
datos.list <- SplitObject(datos.sorted, split.by = "sample" )

# Normalize and find variable features for each 
for (i in 1:length(datos.list)) {
  datos.list[[i]] <- NormalizeData(object = datos.list[[i]])
  datos.list[[i]] <- FindVariableFeatures(object = datos.list[[i]])
 }
```


## Final step: integration.
```{r,  eval=FALSE}
features=SelectIntegrationFeatures(object.list=datos.list)
anchors=FindIntegrationAnchors(object.list=datos.list, anchor.features=features)
datos.integrated=IntegrateData(anchorset=anchors)
```

**Checkpoint for saving our data.**

```{r,  eval=FALSE}

save(datos.integrated, file="datos.integrated.RData")

```


```{r,  eval=FALSE}
#Also in excel format.
write_xlsx(datos.integrated@meta.data, "datosIntegrados.xlsx")

```

What we do next, now with our integrated data, is to rescale, reduce the dimensionality of linear relationships with PCA, and non-linear relationships with UMAP.
```{r,  eval=FALSE}
datos.integrated@meta.data$condition <- NA


datos.integrated@meta.data$condition[which(str_detect(datos.integrated@meta.data$orig.ident, "sm1HI"))] <- "HI"

datos.integrated@meta.data$condition[which(str_detect(datos.integrated@meta.data$orig.ident, "sm2HI"))] <- "HI"

datos.integrated@meta.data$condition[which(str_detect(datos.integrated@meta.data$orig.ident, "sm8SHAM"))] <- "SHAM"

datos.integrated@meta.data$condition[which(str_detect(datos.integrated@meta.data$orig.ident, "sm9SHAM"))] <- "SHAM"
```

We check elbowplot graph for choosing PCs.
```{r, eval=FALSE}
datos.integrated=ScaleData(object=datos.integrated)
datos.integrated=RunPCA(object=datos.integrated)
ElbowPlot(datos.integrated, ndims = 50)

datos.integrated=RunUMAP(object=datos.integrated, dims=1:20)#20 Pcs
DimPlot(datos.integrated, reduction ="umap", group.by="sample")
DimPlot(datos.integrated, reduction ="umap", group.by="condition")
DimPlot(datos.integrated, reduction = "umap", group.by = "experimento")
```




![Samples integrated, divided by sample](datos.integrated.sorted/UMAPsampleIntegrated.png)

![Samples integrated, by condition](datos.integrated.sorted/UMAPconditionIntegrated.png)
![Same, but experiment](datos.integrated.sorted/UMAPexpIntegrated.png)
Due to the integration and batch effect correction, we observe that the separation is exclusively based on the condition, experiment and sample type.

The graphs above show the data *before* integration ("merged" data), while the ones below are *after* integration. In the top graphs, we can clearly see that before integration, the cells separated because they came from different samples and technical variations caused the clustering separation. 

However, in the bottom graphs with our integrated data, the cells are now overlapping and divided into clusters solely due to biological variation.

Now that we have the 20 PCs without batch effect, we proceed with the visualization and clustering of these PCs.

  

```{r,  eval=FALSE}
datos.integrated <- FindNeighbors(datos.integrated)
datos.integrated=FindClusters(datos.integrated, resolution = 0.5)

integrated.sm1HI= subset(datos.integrated, subset= sample=="sm1HI")
integrated.sm2HI= subset(datos.integrated, subset= sample=="sm2HI")
integrated.sm8SHAM= subset(datos.integrated, subset= sample=="sm8SHAM")
integrated.sm9SHAM= subset(datos.integrated, subset= sample=="sm9SHAM")


```


```{r,eval=FALSE}
DimPlot(datos.integrated, reduction = "umap", split.by = "condition") + ggtitle(label = "HI vs SHAM", subtitle = "sorted Cells")

DimPlot(datos.integrated, reduction = "umap", group.by = "integrated_snn_res.0.8", label = TRUE) + ggtitle(label = "res 0.8 Clusters" ,subtitle = "sorted Cells")

DimPlot(integrated.sm1HI, reduction = "umap", group.by = "integrated_snn_res.0.8", label = TRUE) + ggtitle(label = "sm1HI Clusters" ,subtitle = "sorted Cells")

DimPlot(integrated.sm2HI, reduction = "umap", group.by = "integrated_snn_res.0.8", label = TRUE) + ggtitle(label = "sm2HI Clusters" ,subtitle = "sorted Cells")
DimPlot(integrated.sm8SHAM, reduction = "umap", group.by = "integrated_snn_res.0.8", label = TRUE) + ggtitle(label = "sm8SHAM Clusters" ,subtitle = "sorted Cells")
DimPlot(integrated.sm9SHAM, reduction = "umap", group.by = "integrated_snn_res.0.8", label = TRUE) + ggtitle(label = "sm9SHAM Clusters" ,subtitle = "sorted Cells")
```
![UMAP HI vs SHAM](datos.integrated.sorted/sortecHIvsSHAMintegrated.png)
![resolution 0,5; 17 clusters](datos.integrated.sorted/res.05.png)


## Resolution.
We need to test which resolution best fits the annotation(see rmardown "newAnotation", to see the anotation of the clusters).  
To do so, we will try resolutions **0.6** and **0.8** as well.
```{r,  eval=FALSE}
datos.integrated=FindClusters(datos.integrated, resolution = 0.6)
datos.integrated=FindClusters(datos.integrated, resolution = 0.8)
DimPlot(datos.integrated, reduction = "umap", group.by = "integrated_snn_res.0.6", 
        label = TRUE) + ggtitle(label = "Resolución 0.6" ,subtitle = "sorted Cells")
DimPlot(datos.integrated, reduction = "umap", group.by = "integrated_snn_res.0.8", 
        label = TRUE) + ggtitle(label = "Resolución 0.8", subtitle = "sorted Cells")
```
![Resolution: 0.8](datos.integrated.sorted/res.08.png)

We will use resolution 0.8 as the default.
To implement this, we switch back to the integrated assay:

DefaultAssay(datos.integrated) = "integrated"

```{r,  eval=FALSE}
DefaultAssay(datos.integrated)="integrated"
```


```{r,  eval=FALSE}
#These are the tests to find the correct resolution.


datos.integrated=FindClusters(datos.integrated, resolution = 0.9)
datos.integrated=FindClusters(datos.integrated, resolution = 1)
datos.integrated=FindClusters(datos.integrated, resolution = 1.1)
DimPlot(datos.integrated, reduction = "umap", group.by = "integrated_snn_res.0.9", 
        label = TRUE) + ggtitle(label = "Resolución 0.9" ,subtitle = "sorted Cells")
DimPlot(datos.integrated, reduction = "umap", group.by = "integrated_snn_res.1", 
        label = TRUE) + ggtitle(label = "Resolución 1" ,subtitle = "sorted Cells")

DimPlot(datos.integrated, reduction = "umap", group.by = "integrated_snn_res.1.1", 
        label = TRUE) + ggtitle(label = "Resolución 1.1" ,subtitle = "sorted Cells")
```



As we have seen, we chose resolution 0.8.  
From these data, we obtain a table that provides the number of cells per cluster, per sample, and by condition:

```{r,  eval=FALSE}
Idents(datos.integrated)="integrated_snn_res.0.8"
```

Now, we create a summary table:

```{r,eval=FALSE}
cluster_cell_table.sorted <- table(datos.integrated@meta.data$integrated_snn_res.0.8,
                            datos.integrated@meta.data$sample)

cluster_cell_table.sorted <- cbind(cluster_cell_table.sorted
                                   ,cluster_cell_table.sorted[,1]
                                   +cluster_cell_table.sorted[,2]
                                  )

cluster_cell_table.sorted <- cbind(cluster_cell_table.sorted
                                   ,cluster_cell_table.sorted[,3]
                                   +cluster_cell_table.sorted[,4]
                                   )

cluster_cell_table.sorted <- cbind(cluster_cell_table.sorted
                                   ,cluster_cell_table.sorted[,5]
                                   +cluster_cell_table.sorted[,6])


# Get difference in cell number per cluster and per condition (relative to total)
cluster_cell_table.sorted <- cbind(cluster_cell_table.sorted,
                          abs((cluster_cell_table.sorted[,6]-cluster_cell_table.sorted[,5])
                              /cluster_cell_table.sorted[,7]))

colnames(cluster_cell_table.sorted)[5:8] <- c("HI","SHAM","TOTAL","REL.DIFFERENCE")

cluster_cell_table.sorted=as.data.frame(cluster_cell_table.sorted)
```

# Last checkpoint.
At the end, we save our workspace and the table created before as an excell.
```{r, eval=FALSE}
write_xlsx(cluster_cell_table.sorted, "cluster_cell_table.sorted.xlsx")
```
```{r, eval=FALSE}
save(datos.integrated, file= "sorted.RData")
```




